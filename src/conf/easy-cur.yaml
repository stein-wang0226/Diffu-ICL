model:
  n_dims: 20
  n_positions: 101
  family: llada
  n_embd: 256 # == d_model 含义相同， 不同model定义叫法
  d_model: 256
  mlp_ratio: 4.0
  n_layers: 12
  n_heads: 8
  pretrained: false
  hide_last_target: True
  predict_last_only: True
  # model_name_or_path: Qwen/Qwen2.5-7B-Instruct
training:
  task: linear_regression
  task_kwargs: {}
  # num_tasks: 1 # 固定w，会迅速收敛，泛化性差
  data: gaussian
  w_type: gaussian
  batch_size: 64
  learning_rate: 0.0001
  weight_decay: 0
  save_every_steps: 1000
  keep_every_steps: 100000
  # num_training_examples: 5000
  eval_every_steps: 500  # 每n步评估一次
  train_steps: 500001
  curriculum:
    dims:
      start: 5
      end: 5
      inc: 1
      interval: 4000
    points:
      start: 10
      end: 10
      inc: 1
      interval: 4000

wandb:
  project: diffu-ICL-exp
  entity: baojian-fudan-university
  notes: none
  log_every_steps: 100
  name: "standard-llada-no-curr"

out_dir: ./checkpoints/llama