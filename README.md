# ğŸ§  In-Context Learning + DLLM Integration Framework

This repository provides a unified framework that combines **In-Context Learning (ICL)** with **Diffusion Language Models (DLLM)**.  
It supports multiple model families â€” including **Transformer (GPT-2 / GPT-J)**, **LLaDA**, and **Dream** â€” enabling **fair and comparable experiments** between autoregressive and diffusion-based language models.

---

## ğŸ“‚ Project Structure

**dllméœ€è¦importçš„ä¸»è¦æ˜¯/llada/models/modelling_llada ä¸‹çš„æ¨¡å‹class,**

**trainingçš„code å¯ä»¥å‚è€ƒdllm.core.trainersä¸‹çš„é€»è¾‘è‡ªå·±å†™**

```
in-context-learning/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ base_models.py # Base model definitions
â”‚ â”œâ”€â”€ curriculum.py # Curriculum schedule for dynamic task scaling
â”‚ â”œâ”€â”€ eval.py # Evaluation module
â”‚ â”œâ”€â”€ models.py # Model building (GPT, LLaDA, Dream)
â”‚ â”œâ”€â”€ samplers.py # Data sampler
â”‚ â”œâ”€â”€ schema.py # Config schema
â”‚ â”œâ”€â”€ tasks.py # Task definitions (e.g., regression, classification)
â”‚ â”œâ”€â”€ train.py # Unified training loop
â”‚ â””â”€â”€ inference.py # Inference pipeline
â”‚
â””â”€â”€ dllm/ 
    â””â”€â”€ dllm/
    â”œâ”€â”€ pipelines/
    â”‚ â”œâ”€â”€ llada/
    â”‚ â”‚ â”œâ”€â”€ init.py
    â”‚ â”‚ â”œâ”€â”€ generate.py 
    â”‚ â”‚ â””â”€â”€ trainer.py
    â”‚ â””â”€â”€ models/ modelling_llada.py # è¿™é‡Œæ˜¯éœ€è¦import LLaDa model ç±»çš„å®šä¹‰
    â”œâ”€â”€ examples/
    â”‚ â””â”€â”€ llada/
    â”‚ â”œâ”€â”€ pt.py # Pretraining example
    â”‚ â””â”€â”€ sft.py # Finetuning example
    â”œâ”€â”€ utils/ # Helper functions for DLLM
    â”œâ”€â”€ data/ # Data processing
    â””â”€â”€ core/ # æºç 
          â””â”€â”€ trainers/mdlm.py # diffusion trainçš„ä¸»è¦é€»è¾‘

```

âœ… **Supported Models**
- Transformer: GPT-2, GPT-J  ,Llama, ...
- LLaDA: Diffusion-based language model  
- Dream: Optional DLLM alternative

âœ… **Unified API**
- Single `build_model` interface dynamically selects the model type.  
- Compatible with both AR and Diffusion training pipelines.

---

## ğŸ§± 1. Model Definition (`src/models.py`)

We extend the baseline Transformer architecture to include DLLM models.

```python
from dllm.dllm.pipelines.llada.models.configuration_llada import LLaDAConfig
from dllm.dllm.pipelines.llada.models.modeling_llada import LLaDAModelLM as LLaDAModel

def build_model(conf):
    if conf.family == "gpt2":
        model = TransformerModel(...)
    elif conf.family == "gptJ":
        model = TransformerModel(...)
    elif conf.family == "llada":
        config = LLaDAConfig(
            d_model=conf.n_embd,
            n_heads=conf.n_head,
            n_layers=conf.n_layer,
            max_sequence_length=conf.n_positions,
            mlp_ratio=conf.mlp_ratio,
            use_cache=False,
        )
        model = LLaDAModel(config)
    elif conf.family == "dream":
        config = DreamConfig(...)
        model = DreamModel(config)
    else:
        raise NotImplementedError(f"Model family {conf.family} not supported.")
    return model
```

---

## ğŸ‹ï¸ 2. Training Pipeline (`src/train.py`)

This file unifies the **training loop** for both AR (GPT) and DLLM (LLaDA).  
You can **switch models** simply by changing the config file.

Key steps:
1. Load and build model from config  
2. Initialize data/task samplers and curriculum  
3. Run either `train_step_ar` or `train_step_llada`  
4. Log with Weights & Biases  
5. Save checkpoints regularly

```python
def train(model, config, is_llada=False):
    ...
    for step in tqdm(range(starting_step, train_steps)):
        xs = data_sampler.sample_xs(...)
        task = task_sampler()
        ys = task.evaluate(xs)

        if is_llada:
            input_ids = xs.long().to(device)
            loss, _ = train_step_llada(model, input_ids, optimizer)
        else:
            loss, _ = train_step_ar(model, xs.to(device), ys.to(device), optimizer, loss_func)
```

You can resume training from checkpoints using:

```bash
python src/train.py --config configs/llada.yaml
```

---

## âš¡ 3. Environment Setup

### ğŸ“Œ Required Packages (DLLM)
```bash
transformers==4.57.0
accelerate==1.0.1
deepspeed==0.16.3
peft==0.13.2
bitsandbytes==0.42.0
datasets==3.2.0
sentencepiece==0.2.0
trl==0.23.1
tyro
wandb
omegaconf
tqdm
matplotlib
pytest
```

### ğŸ“Œ ICL Environment
```yaml
name: in-context-learning
channels:
  - pytorch
  - defaults
dependencies:
  - pip=21.2.4
  - python=3.8.12
  - pytorch=1.11.0
  - pip:
    - jupyter==1.0.0
    - matplotlib==3.5.2
    - numpy==1.22.3
    - pandas==1.4.2
    - quinine          # install from source if needed
    - scikit-learn==1.0.2
    - seaborn==0.11.2
    - tqdm==4.64.0
    - transformers==4.17.0
    - wandb==0.12.11
    - xgboost==1.6.1
    - protobuf==3.20.1
```

---

## ğŸš€ 4. Run Training

### âœ… Train with LLaDA (DLLM)
```bash
python src/train.py --config configs/llada.yaml
```

### âœ… Train with GPT-2
```bash
python src/train.py --config configs/gpt2.yaml
```

---

## ğŸ“Š 5. Logging and Evaluation

- Training metrics are automatically logged with **Weights & Biases**.  
- Supports curriculum learning: `n_dims` and `n_points` can grow dynamically.  
- Evaluation scripts in `src/eval.py` can be extended for different tasks.

---

## ğŸ§ª 6. Key Features

- ğŸ§  Unified ICL Training Interface for AR and DLLM models  
- ğŸ”€ Dynamic Curriculum Learning for scaling difficulty  
- ğŸ§° Extensible Task Samplers (regression, classification, custom)  
- ğŸ“ Flexible Model Config through YAML  
- ğŸª„ WandB Integration for experiment tracking  
- ğŸ’¾ Checkpointing for robust training resume

---

## ğŸ§­ 7. Roadmap

- [x] Integration of LLaDA model  
- [x] Curriculum training loop  
- [x] GPT / DLLM unified trainer  
- [ ] Tokenizer and prompt engineering for float input  
- [ ] Multi-task evaluation pipeline  
- [ ] Scaling to larger models (e.g., LLaDA-7B)

---

## ğŸ“ Citation

If you find this repository useful, please consider citing:

```
@misc{dllm-icl,
  title  = {In-Context Learning + DLLM Integration Framework},
  author = {Yuxiang et al.},
  year   = {2025},
  note   = {https://github.com/...}
}
```

---

## ğŸ¤ Acknowledgements

- LLaDA: Diffusion Language Model  
- PyTorch: Core deep learning framework  
- Weights & Biases: Logging and visualization  
- Inspired by works on in-context-learning and DLLM research.
